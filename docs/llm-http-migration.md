# LLM HTTP é€šç”¨æ–¹å¼ - è¿ç§»æŒ‡å—

> **é‡å¤§æ›´æ–°**: LLM é›†æˆå·²é‡æ„ä¸ºé€šç”¨ HTTP æ–¹å¼ï¼Œæ— éœ€é¢å¤– SDK åº“ï¼

## ğŸ‰ ä¸»è¦æ”¹è¿›

### 1. **é›¶é¢å¤–ä¾èµ–**
- âŒ æ—§æ–¹å¼ï¼šéœ€è¦å®‰è£… `openai`, `anthropic` ç­‰åº“
- âœ… æ–°æ–¹å¼ï¼šåªéœ€ `jinja2` (ç”¨äº Prompt æ¨¡æ¿)

### 2. **å®Œå…¨é€šç”¨**
- âŒ æ—§æ–¹å¼ï¼šæ¯ä¸ªæä¾›å•†éœ€è¦ä¸“ç”¨ä»£ç 
- âœ… æ–°æ–¹å¼ï¼šé€šè¿‡é…ç½®æ”¯æŒä»»æ„ LLM API

### 3. **æ›´æ˜“æ‰©å±•**
- âŒ æ—§æ–¹å¼ï¼šæ·»åŠ æ–°æä¾›å•†éœ€è¦ç¼–å†™ Python ä»£ç 
- âœ… æ–°æ–¹å¼ï¼šæ·»åŠ æ–°æä¾›å•†åªéœ€ä¸€ä¸ª JSON é…ç½®æ–‡ä»¶

## æ¶æ„å¯¹æ¯”

### æ—§æ¶æ„
```
LLMStrategy â†’ LLMEngine â†’ [OpenAIProvider, AnthropicProvider, OllamaProvider]
                              â†“éœ€è¦ä¸“ç”¨SDK     â†“éœ€è¦ä¸“ç”¨SDK          â†“éœ€è¦ä¸“ç”¨SDK
                           openaiåº“        anthropicåº“          requests
```

### æ–°æ¶æ„
```
LLMStrategy â†’ LLMEngine â†’ HttpLLMProvider
                              â†“ä»…ä½¿ç”¨ requests (å·²å†…ç½®)
                           ä»»æ„ LLM API
```

## é…ç½®è¿ç§»

### æ—§é…ç½®æ ¼å¼

```json
{
    "llm_config": {
        "enabled": true,
        "provider": "openai",      // æ—§å­—æ®µ
        "model": "gpt-4o",
        "api_key": "${OPENAI_API_KEY}",
        "base_url": null,
        "timeout": 30
    }
}
```

### æ–°é…ç½®æ ¼å¼

```json
{
    "llm_config": {
        "enabled": true,
        "provider_type": "http",    // æ–°å­—æ®µï¼Œå›ºå®šä¸º "http"
        "model": "gpt-4o",
        "api_url": "https://api.openai.com/v1/chat/completions",  // æ–°å­—æ®µ
        "api_key": "${OPENAI_API_KEY}",
        "timeout": 30,

        "headers": {                 // æ–°å­—æ®µï¼šHTTP è¯·æ±‚å¤´
            "Authorization": "Bearer {api_key}"
        },

        "request_body": {            // æ–°å­—æ®µï¼šè¯·æ±‚ä½“æ¨¡æ¿
            "model": "{model}",
            "messages": [
                {"role": "user", "content": "{prompt}"}
            ]
        },

        "response_path": {           // æ–°å­—æ®µï¼šå“åº”è§£æ
            "content_path": "choices.0.message.content"
        },

        "cost_config": {             // æ–°å­—æ®µï¼šæˆæœ¬è®¡ç®—
            "input_cost_per_million": 5.0,
            "output_cost_per_million": 15.0
        }
    }
}
```

## è¿ç§»æ­¥éª¤

### æ­¥éª¤ 1: æ›´æ–°ä¾èµ–

```bash
# å¸è½½æ—§åº“ï¼ˆå¯é€‰ï¼‰
pip uninstall openai anthropic

# åªä¿ç•™å¿…è¦çš„åº“
pip install jinja2
```

### æ­¥éª¤ 2: é€‰æ‹©æä¾›å•†é…ç½®

æˆ‘ä»¬ä¸ºå¸¸è§æä¾›å•†æä¾›äº†é…ç½®æ¨¡æ¿ï¼š

```bash
ls config_examples/llm_providers/
# openai.json
# openai-mini.json  (æ¨èï¼šæ€§ä»·æ¯”é«˜)
# anthropic.json
# anthropic-haiku.json
# ollama.json  (æ¨èï¼šå®Œå…¨å…è´¹)
# deepseek.json  (æ¨èï¼šè¶…ä½æˆæœ¬)
# qwen.json
```

### æ­¥éª¤ 3: æ›´æ–°é…ç½®æ–‡ä»¶

æ–¹å¼ A: å¤åˆ¶å®Œæ•´é…ç½®
```bash
# æŸ¥çœ‹æä¾›å•†é…ç½®
cat config_examples/llm_providers/openai-mini.json

# å¤åˆ¶åˆ°ä½ çš„ config.json çš„ llm_config éƒ¨åˆ†
```

æ–¹å¼ B: ä½¿ç”¨é…ç½®ç¤ºä¾‹
```bash
# ä½¿ç”¨æ›´æ–°åçš„é…ç½®ç¤ºä¾‹
cp config_examples/config_llm.example.json user_data/config_llm.json
# å·²åŒ…å« HTTP æ–¹å¼çš„å®Œæ•´é…ç½®
```

### æ­¥éª¤ 4: æµ‹è¯•

```bash
# Dry-run æµ‹è¯•
freqtrade trade -c user_data/config_llm.json --strategy ExampleLLMStrategy

# æŸ¥çœ‹æ—¥å¿—ç¡®è®¤ HTTP æ–¹å¼æ­£å¸¸å·¥ä½œ
tail -f user_data/logs/freqtrade.log | grep "HTTP LLM"
```

## æä¾›å•†é…ç½®æ¨¡æ¿

### OpenAI (GPT-4o-mini) - æ¨è

```json
{
    "provider_type": "http",
    "model": "gpt-4o-mini",
    "api_url": "https://api.openai.com/v1/chat/completions",
    "api_key": "${OPENAI_API_KEY}",
    "headers": {
        "Authorization": "Bearer {api_key}"
    },
    "request_body": {
        "model": "{model}",
        "messages": [{"role": "user", "content": "{prompt}"}],
        "response_format": {"type": "json_object"}
    },
    "response_path": {
        "content_path": "choices.0.message.content"
    },
    "cost_config": {
        "input_cost_per_million": 0.15,
        "output_cost_per_million": 0.6
    }
}
```

### Anthropic (Claude 3 Haiku) - å¿«é€Ÿä¸”ä¾¿å®œ

```json
{
    "provider_type": "http",
    "model": "claude-3-haiku-20240307",
    "api_url": "https://api.anthropic.com/v1/messages",
    "api_key": "${ANTHROPIC_API_KEY}",
    "headers": {
        "x-api-key": "{api_key}",
        "anthropic-version": "2023-06-01"
    },
    "request_body": {
        "model": "{model}",
        "max_tokens": 1024,
        "messages": [{"role": "user", "content": "{prompt}"}]
    },
    "response_path": {
        "content_path": "content.0.text"
    },
    "cost_config": {
        "input_cost_per_million": 0.25,
        "output_cost_per_million": 1.25
    }
}
```

### Ollama (æœ¬åœ°) - å®Œå…¨å…è´¹

```json
{
    "provider_type": "http",
    "model": "llama3",
    "api_url": "http://localhost:11434/api/generate",
    "headers": {},
    "request_body": {
        "model": "{model}",
        "prompt": "{prompt}",
        "stream": false,
        "format": "json"
    },
    "response_path": {
        "content_path": "response"
    },
    "cost_config": {
        "input_cost_per_million": 0.0,
        "output_cost_per_million": 0.0
    }
}
```

### DeepSeek - è¶…ä½æˆæœ¬

```json
{
    "provider_type": "http",
    "model": "deepseek-chat",
    "api_url": "https://api.deepseek.com/v1/chat/completions",
    "api_key": "${DEEPSEEK_API_KEY}",
    "headers": {
        "Authorization": "Bearer {api_key}"
    },
    "request_body": {
        "model": "{model}",
        "messages": [{"role": "user", "content": "{prompt}"}],
        "response_format": {"type": "json_object"}
    },
    "response_path": {
        "content_path": "choices.0.message.content"
    },
    "cost_config": {
        "input_cost_per_million": 0.27,
        "output_cost_per_million": 1.10
    }
}
```

## å ä½ç¬¦è¯´æ˜

é…ç½®ä¸­å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å ä½ç¬¦ï¼š

| å ä½ç¬¦ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|
| `{api_key}` | API å¯†é’¥ | `"Authorization": "Bearer {api_key}"` |
| `{model}` | æ¨¡å‹åç§° | `"model": "{model}"` |
| `{prompt}` | ç”¨æˆ·æç¤ºè¯ | `"content": "{prompt}"` |
| `{temperature}` | æ¸©åº¦å‚æ•° | `"temperature": "{temperature}"` |

## å“åº”è·¯å¾„è¯­æ³•

ä½¿ç”¨ç‚¹å· `.` è¡¨ç¤º JSON è·¯å¾„ï¼š

| è·¯å¾„ | è¯´æ˜ | å¯¹åº”çš„ Python |
|------|------|--------------|
| `"choices.0.message.content"` | æ•°ç»„ç´¢å¼•ç”¨æ•°å­— | `response["choices"][0]["message"]["content"]` |
| `"content.0.text"` | åµŒå¥—è·¯å¾„ | `response["content"][0]["text"]` |
| `"response"` | é¡¶å±‚å­—æ®µ | `response["response"]` |

å¦‚æœæœªæŒ‡å®šè·¯å¾„ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•å¸¸è§æ ¼å¼ã€‚

## å…¼å®¹æ€§è¯´æ˜

### æ—§ä»£ç ä»ç„¶å¯ç”¨

æ—§çš„ä¸“ç”¨æä¾›å•†ä»£ç ä»ç„¶ä¿ç•™ï¼ˆæ ‡è®°ä¸º deprecatedï¼‰ï¼š

```json
{
    "llm_config": {
        "provider_type": "openai_legacy",  // ä½¿ç”¨æ—§ä»£ç 
        // ...
    }
}
```

ä½†æˆ‘ä»¬**å¼ºçƒˆæ¨è**ä½¿ç”¨æ–°çš„ HTTP æ–¹å¼ã€‚

### é€æ­¥è¿ç§»

1. å…ˆåœ¨æµ‹è¯•ç¯å¢ƒä½¿ç”¨ HTTP æ–¹å¼
2. ç¡®è®¤å·¥ä½œæ­£å¸¸åå†åˆ‡æ¢ç”Ÿäº§ç¯å¢ƒ
3. å¯ä»¥åŒæ—¶è¿è¡Œä¸¤ä¸ªé…ç½®è¿›è¡Œå¯¹æ¯”

## æˆæœ¬å¯¹æ¯”

| æä¾›å•† | æˆæœ¬/å†³ç­– | æœˆæˆæœ¬ (5m æ—¶é—´æ¡†æ¶) |
|--------|----------|-------------------|
| **Ollama (æœ¬åœ°)** | **$0** | **$0** |
| **DeepSeek** | $0.0007 | ~$6 |
| **GPT-4o-mini** | $0.0004 | ~$3.5 |
| **Claude Haiku** | $0.0007 | ~$6 |
| GPT-4o | $0.010 | ~$86 |

## æ€§èƒ½å¯¹æ¯”

| æä¾›å•† | å¹³å‡å»¶è¿Ÿ | æœ¬åœ°/äº‘ç«¯ |
|--------|---------|----------|
| **Ollama** | 200ms | æœ¬åœ° |
| GPT-4o-mini | 400ms | äº‘ç«¯ |
| Claude Haiku | 500ms | äº‘ç«¯ |
| DeepSeek | 600ms | äº‘ç«¯ |
| GPT-4o | 800ms | äº‘ç«¯ |

## æ–‡ä»¶å˜æ›´æ¸…å•

### æ–°å¢æ–‡ä»¶

```
freqtrade/llm/providers/http_provider.py  # HTTP é€šç”¨æä¾›å•†
config_examples/llm_providers/
â”œâ”€â”€ README.md
â”œâ”€â”€ openai.json
â”œâ”€â”€ openai-mini.json
â”œâ”€â”€ anthropic.json
â”œâ”€â”€ anthropic-haiku.json
â”œâ”€â”€ ollama.json
â”œâ”€â”€ deepseek.json
â””â”€â”€ qwen.json
docs/llm-quick-start-http.md             # HTTP å¿«é€Ÿå…¥é—¨
docs/llm-http-migration.md               # æœ¬æ–‡æ¡£
```

### ä¿®æ”¹æ–‡ä»¶

```
freqtrade/llm/providers/__init__.py       # å¯¼å‡º HttpLLMProvider
freqtrade/llm/engine.py                   # ä½¿ç”¨ provider_type
config_examples/config_llm.example.json   # æ›´æ–°ä¸º HTTP é…ç½®
requirements-llm.txt                      # ç§»é™¤ openai, anthropic
requirements-add.txt                      # ç§»é™¤ openai, anthropic
```

### ä¿ç•™æ–‡ä»¶ (æ ‡è®°ä¸º deprecated)

```
freqtrade/llm/providers/openai_provider.py
freqtrade/llm/providers/anthropic_provider.py
freqtrade/llm/providers/ollama_provider.py
```

## å¸¸è§é—®é¢˜

### Q: æ—§é…ç½®è¿˜èƒ½ç”¨å—ï¼Ÿ

A: å¯ä»¥ï¼Œä½†éœ€è¦å°† `"provider": "openai"` æ”¹ä¸º `"provider_type": "openai_legacy"`ã€‚ä¸è¿‡æˆ‘ä»¬å¼ºçƒˆæ¨èè¿ç§»åˆ° HTTP æ–¹å¼ã€‚

### Q: HTTP æ–¹å¼æœ‰ä»€ä¹ˆé™åˆ¶å—ï¼Ÿ

A: å‡ ä¹æ²¡æœ‰ã€‚åªè¦ LLM æä¾› HTTP APIï¼Œå°±å¯ä»¥é€šè¿‡é…ç½®ä½¿ç”¨ã€‚

### Q: å¦‚ä½•æ·»åŠ æ–°çš„ LLM æä¾›å•†ï¼Ÿ

A: åˆ›å»ºä¸€ä¸ª JSON é…ç½®æ–‡ä»¶å³å¯ï¼Œæ— éœ€ç¼–å†™ä»£ç ã€‚å‚è€ƒ `config_examples/llm_providers/` ä¸­çš„ç¤ºä¾‹ã€‚

### Q: æ€§èƒ½ä¼šå—å½±å“å—ï¼Ÿ

A: ä¸ä¼šã€‚HTTP æ–¹å¼ä½¿ç”¨ `requests` åº“ï¼Œæ€§èƒ½ä¸ä¸“ç”¨ SDK ç›¸å½“æˆ–æ›´å¥½ï¼ˆå› ä¸ºå‡å°‘äº†ä¸­é—´å±‚ï¼‰ã€‚

### Q: æˆæœ¬è®¡ç®—å‡†ç¡®å—ï¼Ÿ

A: æ˜¯çš„ã€‚`cost_config` å¯ä»¥ç²¾ç¡®é…ç½®æ¯ä¸ªæä¾›å•†çš„å®šä»·ã€‚

## è·å–å¸®åŠ©

- æŸ¥çœ‹æä¾›å•†é…ç½®: `config_examples/llm_providers/README.md`
- å¿«é€Ÿå…¥é—¨: `docs/llm-quick-start-http.md`
- è®¾è®¡æ–‡æ¡£: `docs/llm-strategy-design.md`
- GitHub Issues: https://github.com/freqtrade/freqtrade/issues

## æ€»ç»“

âœ… **æ›´ç®€å•**: æ— éœ€é¢å¤– SDKï¼Œåªéœ€ requests
âœ… **æ›´é€šç”¨**: æ”¯æŒä»»æ„ LLM API
âœ… **æ›´çµæ´»**: é€šè¿‡é…ç½®å³å¯é€‚é…
âœ… **æ›´ä¾¿å®œ**: æ”¯æŒæœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰å’Œä½æˆæœ¬é€‰é¡¹ï¼ˆDeepSeekï¼‰

**ç«‹å³è¿ç§»åˆ° HTTP æ–¹å¼ï¼Œäº«å—æ›´å¥½çš„ LLM é›†æˆä½“éªŒï¼** ğŸš€
