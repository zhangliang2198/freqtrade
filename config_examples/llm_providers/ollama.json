{
    "_comment": "Ollama Local LLM Configuration (完全免费)",
    "provider_type": "http",
    "model": "llama3",
    "api_url": "http://localhost:11434/api/generate",
    "timeout": 60,
    "max_retries": 2,
    "temperature": 0.1,

    "headers": {
        "Content-Type": "application/json"
    },

    "request_body": {
        "model": "{model}",
        "prompt": "{prompt}\n\nIMPORTANT: Respond ONLY with valid JSON in the specified format. No other text, explanations, or markdown formatting.",
        "temperature": "{temperature}",
        "stream": false,
        "format": "json"
    },

    "response_path": {
        "content_path": "response",
        "usage_path": null,
        "ensure_json": true
    },

    "cost_config": {
        "_comment": "Ollama is free (local model)",
        "input_cost_per_million": 0.0,
        "output_cost_per_million": 0.0
    }
}
