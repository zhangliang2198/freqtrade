# LLM è¾…åŠ©äº¤æ˜“ç­–ç•¥ - å¿«é€Ÿå…¥é—¨ (HTTP é€šç”¨æ–¹å¼)

## æ¦‚è¿°

**é‡å¤§æ›´æ–°**ï¼šçŽ°åœ¨ä½¿ç”¨ç»Ÿä¸€çš„ HTTP æŽ¥å£è°ƒç”¨æ‰€æœ‰ LLMï¼Œæ— éœ€å®‰è£…ä»»ä½•é¢å¤–çš„ SDK åº“ï¼

åªéœ€è¦é…ç½® API URLã€è¯·æ±‚æ ¼å¼å’Œå“åº”æ ¼å¼ï¼Œå°±å¯ä»¥æ”¯æŒä»»ä½• LLM æä¾›å•†ã€‚

## ä¼˜åŠ¿

âœ… **é›¶é¢å¤–ä¾èµ–** - åªéœ€ `jinja2`ï¼ˆç”¨äºŽ Prompt æ¨¡æ¿ï¼‰
âœ… **é€šç”¨æ€§å¼º** - æ”¯æŒä»»ä½•æä¾› HTTP API çš„ LLM
âœ… **é…ç½®çµæ´»** - é€šè¿‡ JSON é…ç½®é€‚é…ä¸åŒæä¾›å•†
âœ… **æ˜“äºŽæ‰©å±•** - æ·»åŠ æ–°æä¾›å•†åªéœ€ä¸€ä¸ªé…ç½®æ–‡ä»¶

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–ï¼ˆåªéœ€ jinja2ï¼‰

```bash
pip install jinja2
```

å°±è¿™ä¹ˆç®€å•ï¼ä¸éœ€è¦ `openai`ã€`anthropic` ç­‰åº“ã€‚

### 2. é€‰æ‹© LLM æä¾›å•†

æˆ‘ä»¬æä¾›äº†å¤šä¸ªæä¾›å•†çš„é…ç½®æ¨¡æ¿ï¼š

| æä¾›å•† | æˆæœ¬ | é…ç½®æ–‡ä»¶ | æŽ¨èåœºæ™¯ |
|--------|------|---------|---------|
| **OpenAI GPT-4o-mini** | ðŸ’° $0.0004/å†³ç­– | `openai-mini.json` | **æœ€ä½³æ€§ä»·æ¯”** |
| **Ollama** | ðŸ’° **å®Œå…¨å…è´¹** | `ollama.json` | **é›¶æˆæœ¬æ–¹æ¡ˆ** |
| **DeepSeek** | ðŸ’° $0.0007/å†³ç­– | `deepseek.json` | **è¶…ä½Žæˆæœ¬** |
| **Claude Haiku** | ðŸ’° $0.0007/å†³ç­– | `anthropic-haiku.json` | **å¿«é€Ÿå“åº”** |
| OpenAI GPT-4o | ðŸ’° $0.010/å†³ç­– | `openai.json` | é«˜è´¨é‡å†³ç­– |
| Claude 3.5 | ðŸ’° $0.009/å†³ç­– | `anthropic.json` | é«˜è´¨é‡å†³ç­– |
| é€šä¹‰åƒé—® | ðŸ’° $0.001/å†³ç­– | `qwen.json` | å›½å†…ç”¨æˆ· |

### 3. é…ç½® API

#### æ–¹å¼ A: ä½¿ç”¨é¢„è®¾é…ç½®ï¼ˆæŽ¨èï¼‰

```bash
# æŸ¥çœ‹æä¾›å•†é…ç½®
ls config_examples/llm_providers/
# openai.json openai-mini.json anthropic.json ollama.json deepseek.json qwen.json

# å¤åˆ¶ä¸»é…ç½®
cp config_examples/config_llm.example.json user_data/config_llm.json

# é€‰æ‹©ä¸€ä¸ªæä¾›å•†é…ç½®ï¼Œå¤åˆ¶å…¶å†…å®¹åˆ° config_llm.json çš„ llm_config éƒ¨åˆ†
cat config_examples/llm_providers/openai-mini.json
```

#### æ–¹å¼ B: æ‰‹åŠ¨é…ç½®

ç¼–è¾‘ `user_data/config_llm.json`ï¼Œæ·»åŠ  LLM é…ç½®ï¼š

```json
{
    "llm_config": {
        "enabled": true,
        "provider_type": "http",
        "model": "gpt-4o-mini",
        "api_url": "https://api.openai.com/v1/chat/completions",
        "api_key": "${OPENAI_API_KEY}",

        "headers": {
            "Content-Type": "application/json",
            "Authorization": "Bearer {api_key}"
        },

        "request_body": {
            "model": "{model}",
            "messages": [
                {"role": "system", "content": "You are a crypto trading expert."},
                {"role": "user", "content": "{prompt}"}
            ],
            "temperature": "{temperature}",
            "response_format": {"type": "json_object"}
        },

        "response_path": {
            "content_path": "choices.0.message.content",
            "ensure_json": true
        },

        "cost_config": {
            "input_cost_per_million": 0.15,
            "output_cost_per_million": 0.6
        },

        "decision_points": {
            "entry": {"enabled": true, "confidence_threshold": 0.7},
            "exit": {"enabled": true, "confidence_threshold": 0.6}
        }
    }
}
```

### 4. è®¾ç½® API å¯†é’¥

```bash
# OpenAI
export OPENAI_API_KEY="sk-your-key"

# Anthropic
export ANTHROPIC_API_KEY="sk-ant-your-key"

# DeepSeek
export DEEPSEEK_API_KEY="sk-your-key"

# é€šä¹‰åƒé—®
export DASHSCOPE_API_KEY="sk-your-key"

# Ollama ä¸éœ€è¦ API Key (æœ¬åœ°è¿è¡Œ)
```

### 5. è¿è¡Œç­–ç•¥

```bash
# Dry-run æ¨¡å¼ï¼ˆæŽ¨èå…ˆæµ‹è¯•ï¼‰
freqtrade trade -c user_data/config_llm.json --strategy ExampleLLMStrategy

# Live æ¨¡å¼ï¼ˆè°¨æ…Žï¼ï¼‰
freqtrade trade -c user_data/config_llm.json --strategy ExampleLLMStrategy --dry-run=false
```

## é…ç½®è¯¦è§£

### HTTP è¯·æ±‚é…ç½®

#### å ä½ç¬¦

åœ¨ `headers` å’Œ `request_body` ä¸­å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å ä½ç¬¦ï¼š

- `{api_key}` - æ›¿æ¢ä¸º API å¯†é’¥
- `{model}` - æ›¿æ¢ä¸ºæ¨¡åž‹åç§°
- `{prompt}` - æ›¿æ¢ä¸ºç”¨æˆ·æç¤ºè¯
- `{temperature}` - æ›¿æ¢ä¸ºæ¸©åº¦å‚æ•°

#### å“åº”è§£æž

`response_path` é…ç½®å¦‚ä½•ä»Žå“åº”ä¸­æå–å†…å®¹ï¼š

```json
{
    "response_path": {
        "content_path": "choices.0.message.content",  // JSON è·¯å¾„ï¼ˆä½¿ç”¨ . åˆ†éš”ï¼‰
        "usage_path": "usage",                         // Token ä½¿ç”¨ä¿¡æ¯è·¯å¾„
        "ensure_json": true                            // è‡ªåŠ¨æå– JSON
    }
}
```

**è·¯å¾„è¯­æ³•**ï¼š
- `"choices.0.message.content"` â†’ `response["choices"][0]["message"]["content"]`
- æ•°å­—è¡¨ç¤ºæ•°ç»„ç´¢å¼•

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: ä½¿ç”¨ GPT-4o-mini (æœ€ä½³æ€§ä»·æ¯”)

```bash
# 1. è®¾ç½® API Key
export OPENAI_API_KEY="sk-..."

# 2. å¤åˆ¶é…ç½®
cat > user_data/config_llm.json << 'EOF'
{
    "strategy": "ExampleLLMStrategy",
    "llm_config": {
        "enabled": true,
        "provider_type": "http",
        "model": "gpt-4o-mini",
        "api_url": "https://api.openai.com/v1/chat/completions",
        "api_key": "${OPENAI_API_KEY}",
        "headers": {
            "Authorization": "Bearer {api_key}"
        },
        "request_body": {
            "model": "{model}",
            "messages": [
                {"role": "user", "content": "{prompt}"}
            ],
            "response_format": {"type": "json_object"}
        },
        "response_path": {
            "content_path": "choices.0.message.content"
        },
        "cost_config": {
            "input_cost_per_million": 0.15,
            "output_cost_per_million": 0.6
        },
        "decision_points": {
            "entry": {"enabled": true}
        }
    }
}
EOF

# 3. è¿è¡Œ
freqtrade trade -c user_data/config_llm.json --strategy ExampleLLMStrategy
```

### ç¤ºä¾‹ 2: ä½¿ç”¨ Ollama (å®Œå…¨å…è´¹)

```bash
# 1. å®‰è£…å¹¶å¯åŠ¨ Ollama
ollama pull llama3
ollama serve &

# 2. å¤åˆ¶ Ollama é…ç½®
cp config_examples/llm_providers/ollama.json user_data/ollama_config.json

# 3. åœ¨ä¸»é…ç½®ä¸­å¼•ç”¨
cat user_data/config_llm.json  # å°† ollama_config.json çš„å†…å®¹å¤åˆ¶åˆ° llm_config

# 4. è¿è¡Œï¼ˆæ— éœ€ API Keyï¼ï¼‰
freqtrade trade -c user_data/config_llm.json --strategy ExampleLLMStrategy
```

### ç¤ºä¾‹ 3: ä½¿ç”¨ DeepSeek (è¶…ä¾¿å®œ)

```bash
# 1. è®¾ç½® API Key
export DEEPSEEK_API_KEY="sk-..."

# 2. ä½¿ç”¨ DeepSeek é…ç½®
# å¤åˆ¶ config_examples/llm_providers/deepseek.json åˆ°ä½ çš„é…ç½®

# 3. è¿è¡Œ
freqtrade trade -c user_data/config_llm.json --strategy ExampleLLMStrategy
```

## ç›‘æŽ§å’Œè°ƒè¯•

### æŸ¥çœ‹æ—¥å¿—

```bash
# å®žæ—¶æ—¥å¿—
tail -f user_data/logs/freqtrade.log | grep LLM

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼ï¼š
# LLM decision for BTC/USDT entry: buy (confidence: 0.85, latency: 450ms, cost: $0.0004)
```

### æŸ¥è¯¢æ•°æ®åº“

```python
from freqtrade.persistence import Trade
from freqtrade.persistence.llm_models import LLMDecision

# æœ€è¿‘ 10 æ¬¡å†³ç­–
decisions = Trade.session.query(LLMDecision)\
    .order_by(LLMDecision.created_at.desc())\
    .limit(10).all()

for d in decisions:
    print(f"{d.pair} {d.decision_point}: {d.decision} (conf: {d.confidence:.2f}, cost: ${d.cost_usd:.4f})")
```

### Prometheus æŒ‡æ ‡

```bash
# å¯åŠ¨ exporter
python exporter/freqtrade_exporter.py --port 9999

# æŸ¥çœ‹ LLM æŒ‡æ ‡
curl http://localhost:9999/metrics | grep llm

# å…³é”®æŒ‡æ ‡:
# - freqtrade_llm_total_calls: æ€»è°ƒç”¨æ¬¡æ•°
# - freqtrade_llm_total_cost_usd: ç´¯è®¡æˆæœ¬
# - freqtrade_llm_success_rate: æˆåŠŸçŽ‡
# - freqtrade_llm_entry_win_rate: å…¥åœºå†³ç­–èƒœçŽ‡
```

## æˆæœ¬ç®¡ç†

### æœˆåº¦æˆæœ¬ä¼°ç®—

å‡è®¾ 5 åˆ†é’Ÿæ—¶é—´æ¡†æž¶ï¼Œæ¯ 5 åˆ†é’Ÿ 1 æ¬¡å†³ç­–ï¼š

| æä¾›å•† | æ¯æ¬¡ | æ¯å¤© | æ¯æœˆ |
|--------|------|------|------|
| **Ollama (æœ¬åœ°)** | **$0** | **$0** | **$0** |
| **DeepSeek** | $0.0007 | $0.20 | $6 |
| **GPT-4o-mini** | $0.0004 | $0.12 | $3.5 |
| **Claude Haiku** | $0.0007 | $0.20 | $6 |
| GPT-4o | $0.010 | $2.88 | $86 |

### é™ä½Žæˆæœ¬æŠ€å·§

1. **ä½¿ç”¨ç¼“å­˜**ï¼š
```json
{
    "decision_points": {
        "entry": {
            "cache_ttl": 300  // 5åˆ†é’Ÿç¼“å­˜ï¼Œç›¸åŒå¸‚åœºæ¡ä»¶å¤ç”¨å†³ç­–
        }
    }
}
```

2. **å‡å°‘ä¸Šä¸‹æ–‡**ï¼š
```json
{
    "context": {
        "lookback_candles": 50,  // å‡å°‘åŽ†å²æ•°æ®
        "include_indicators": ["rsi", "macd"]  // åªåŒ…å«å¿…è¦æŒ‡æ ‡
    }
}
```

3. **ä½¿ç”¨ä¾¿å®œ/å…è´¹æ¨¡åž‹**ï¼š
   - **Ollama**: å®Œå…¨å…è´¹
   - **DeepSeek**: è¶…ä¾¿å®œ
   - **GPT-4o-mini**: OpenAI æœ€ä¾¿å®œçš„é€‰é¡¹

4. **æé«˜ç½®ä¿¡åº¦é˜ˆå€¼**ï¼š
```json
{
    "decision_points": {
        "entry": {
            "confidence_threshold": 0.8  // åªåœ¨é«˜ç½®ä¿¡åº¦æ—¶å…¥åœº
        }
    }
}
```

## æ·»åŠ è‡ªå®šä¹‰ LLM

ä½ å¯ä»¥æ·»åŠ ä»»ä½•æä¾› HTTP API çš„ LLMï¼š

```json
{
    "llm_config": {
        "provider_type": "http",
        "model": "your-model",
        "api_url": "https://your-api.com/v1/chat",
        "api_key": "${YOUR_API_KEY}",

        "headers": {
            "Authorization": "Bearer {api_key}"
        },

        "request_body": {
            "model": "{model}",
            "input": "{prompt}"
        },

        "response_path": {
            "content_path": "output.text",
            "ensure_json": true
        },

        "cost_config": {
            "input_cost_per_million": 1.0,
            "output_cost_per_million": 2.0
        }
    }
}
```

## å¸¸è§é—®é¢˜

### Q: å“åº”ä¸æ˜¯ JSON æ ¼å¼æ€Žä¹ˆåŠžï¼Ÿ

A: ç¡®ä¿è®¾ç½® `"ensure_json": true`ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æå– JSONã€‚ä¹Ÿå¯ä»¥åœ¨ prompt ä¸­å¼ºè°ƒ JSON æ ¼å¼ã€‚

### Q: å¦‚ä½•çŸ¥é“å“åº”è·¯å¾„ï¼Ÿ

A: æŸ¥çœ‹ API æ–‡æ¡£ï¼Œæˆ–è€…å…ˆæ‰‹åŠ¨è°ƒç”¨ä¸€æ¬¡æŸ¥çœ‹å“åº”ç»“æž„ã€‚å¸¸è§è·¯å¾„ï¼š
- OpenAI: `"choices.0.message.content"`
- Anthropic: `"content.0.text"`
- å…¶ä»–: å¦‚æžœæœªæŒ‡å®šä¼šè‡ªåŠ¨å°è¯•å¸¸è§è·¯å¾„

### Q: Ollama å»¶è¿Ÿå¤ªé«˜ï¼Ÿ

A: ä½¿ç”¨ GPU åŠ é€Ÿï¼š
```bash
# å®‰è£… CUDA ç‰ˆæœ¬çš„ Ollama
# æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡åž‹
ollama pull llama3:8b  # ä½¿ç”¨ 8B å‚æ•°ç‰ˆæœ¬è€Œéž 70B
```

### Q: å¦‚ä½•æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ

A: è¿è¡Œ dry-run æ¨¡å¼å¹¶æŸ¥çœ‹æ—¥å¿—ï¼Œåº”è¯¥çœ‹åˆ° LLM å†³ç­–æ—¥å¿—ã€‚

## ä¸‹ä¸€æ­¥

- ðŸ“– [å®Œæ•´è®¾è®¡æ–‡æ¡£](llm-strategy-design.md) - æ·±å…¥äº†è§£æž¶æž„
- ðŸ“Š [æä¾›å•†é…ç½®æ¨¡æ¿](../config_examples/llm_providers/) - æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æä¾›å•†
- ðŸ’¡ [ç¤ºä¾‹ç­–ç•¥](../user_data/strategies/ExampleLLMStrategy.py) - å­¦ä¹ å¦‚ä½•åˆ›å»ºç­–ç•¥

## èŽ·å–å¸®åŠ©

- é…ç½®é—®é¢˜: æŸ¥çœ‹ `config_examples/llm_providers/README.md`
- GitHub Issues: https://github.com/freqtrade/freqtrade/issues
- Discord: https://discord.gg/freqtrade

ç¥äº¤æ˜“é¡ºåˆ©ï¼ðŸš€
